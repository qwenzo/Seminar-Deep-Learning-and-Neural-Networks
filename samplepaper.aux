\relax 
\providecommand\@newglossary[4]{}
\@newglossary{main}{glg}{gls}{glo}
\@newglossary{acronym}{alg}{acr}{acn}
\@writefile{toc}{\contentsline {title}{Neural Networks and Deep Learning \unskip {}}{1}\protected@file@percent }
\@writefile{toc}{\authcount {3}}
\@writefile{toc}{\contentsline {author}{Mohamed Hesham Ibrahim Abdalla \and Second Author \and Third Author}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Mathematical Background and Concept}{1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Forward Propagation}{1}\protected@file@percent }
\newlabel{nn}{{2.1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) A single-layer \gls {ann} where the first layer has only one neuron. (b) A multi-layer \gls {ann} with 2 hidden layers. }}{2}\protected@file@percent }
\newlabel{z}{{1}{2}}
\newlabel{a}{{2}{2}}
\newlabel{zvec}{{3}{2}}
\newlabel{zvec}{{4}{2}}
\citation{lemarechal2012cauchy}
\newlabel{b}{{5}{3}}
\newlabel{nls}{{2.1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example of a linear activation function on non linearly separable data https://www.r-bloggers.com/interactive-visualization-of-non-linear-logistic-regression-decision-boundaries-with-shiny/}}{3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Backward Propagation}{3}\protected@file@percent }
\bibstyle{splncs04}
\bibdata{refs}
\bibcite{lemarechal2012cauchy}{1}
\newlabel{gd}{{2.2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Gradient descent visualization https://docs.paperspace.com/machine-learning/wiki/gradient-descent}}{4}\protected@file@percent }
\newlabel{gdu}{{6}{4}}
\newlabel{gdu}{{7}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces diffrent Activation functions.}}{5}\protected@file@percent }
\newlabel{tab1}{{1}{5}}
